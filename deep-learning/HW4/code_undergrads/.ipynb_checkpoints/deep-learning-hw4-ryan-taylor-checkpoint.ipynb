{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T20:47:09.657732Z","iopub.execute_input":"2022-04-27T20:47:09.658424Z","iopub.status.idle":"2022-04-27T20:47:11.547686Z","shell.execute_reply.started":"2022-04-27T20:47:09.658384Z","shell.execute_reply":"2022-04-27T20:47:11.546946Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:11.549770Z","iopub.execute_input":"2022-04-27T20:47:11.550176Z","iopub.status.idle":"2022-04-27T20:47:12.233813Z","shell.execute_reply.started":"2022-04-27T20:47:11.550140Z","shell.execute_reply":"2022-04-27T20:47:12.232786Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#supress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:12.237025Z","iopub.execute_input":"2022-04-27T20:47:12.237346Z","iopub.status.idle":"2022-04-27T20:47:12.956390Z","shell.execute_reply.started":"2022-04-27T20:47:12.237312Z","shell.execute_reply":"2022-04-27T20:47:12.955666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\ndirectories = ['../input/csc4851-homework4/birds_400/test',\n                                '../input/csc4851-homework4/birds_400/train',\n                                '../input//csc4851-homework4/birds_400/valid']\n\nfor dir in directories:\n    label = []\n    path = []\n    for dirname, _,filenames in os.walk(dir):\n        for filename in filenames:\n            label.append(os.path.split(dirname)[1])\n            path.append(os.path.join(dirname,filename))\n    if dir == directories[0]:\n        df_test = pd.DataFrame(columns=['path','label'])\n        df_test['path']=path\n        df_test['label']=label\n    elif dir == directories[1]:\n        df_train = pd.DataFrame(columns=['path','label'])\n        df_train['path']=path\n        df_train['label']=label        \n    elif dir == directories[2]:\n        df_valid = pd.DataFrame(columns=['path','label'])\n        df_valid['path']=path\n        df_valid['label']=label\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:12.958341Z","iopub.execute_input":"2022-04-27T20:47:12.958583Z","iopub.status.idle":"2022-04-27T20:47:20.793328Z","shell.execute_reply.started":"2022-04-27T20:47:12.958534Z","shell.execute_reply":"2022-04-27T20:47:20.792535Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:20.794959Z","iopub.execute_input":"2022-04-27T20:47:20.795510Z","iopub.status.idle":"2022-04-27T20:47:20.811799Z","shell.execute_reply.started":"2022-04-27T20:47:20.795469Z","shell.execute_reply":"2022-04-27T20:47:20.811091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Display 20 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\ndf_sample = df_train.sample(15)\ndf_sample.reset_index(drop=True, inplace=True)\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_sample.path[i]))\n    ax.set_title(df_sample.label[i])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:20.813311Z","iopub.execute_input":"2022-04-27T20:47:20.813795Z","iopub.status.idle":"2022-04-27T20:47:22.108226Z","shell.execute_reply.started":"2022-04-27T20:47:20.813758Z","shell.execute_reply":"2022-04-27T20:47:22.107603Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Hyper Params\nlearning_rate = 0.01\nnum_classes = 400\nbatch_size = 30","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:22.109131Z","iopub.execute_input":"2022-04-27T20:47:22.109334Z","iopub.status.idle":"2022-04-27T20:47:22.114500Z","shell.execute_reply.started":"2022-04-27T20:47:22.109306Z","shell.execute_reply":"2022-04-27T20:47:22.113611Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform_dict = transforms.Compose([transforms.Resize((120, 120)),\n                                    transforms.RandomResizedCrop(120),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.5],[0.4])\n                                    ])\n\ntrain_data = torchvision.datasets.ImageFolder(root=directories[1], transform=transform_dict)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4)\n\ntest_data = torchvision.datasets.ImageFolder(root=directories[0], transform=transform_dict)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4)\n\nvalid_data = torchvision.datasets.ImageFolder(root=directories[2], transform=transform_dict)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=5, shuffle=False, drop_last=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:22.116028Z","iopub.execute_input":"2022-04-27T20:47:22.116661Z","iopub.status.idle":"2022-04-27T20:47:22.956898Z","shell.execute_reply.started":"2022-04-27T20:47:22.116626Z","shell.execute_reply":"2022-04-27T20:47:22.956167Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n        self.pool1 = nn.MaxPool2d(2)\n        self.pool2 = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(64*6*6, 256)\n        self.fc2 = nn.Linear(256, 400)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(self.pool1(x))\n        x = F.relu(F.max_pool2d(self.conv3(x),2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(self.pool2(x))\n\n        x = x.view(-1,64*6*6)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:22.958310Z","iopub.execute_input":"2022-04-27T20:47:22.958571Z","iopub.status.idle":"2022-04-27T20:47:22.969227Z","shell.execute_reply.started":"2022-04-27T20:47:22.958517Z","shell.execute_reply":"2022-04-27T20:47:22.968363Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = CNN(num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:22.972238Z","iopub.execute_input":"2022-04-27T20:47:22.973066Z","iopub.status.idle":"2022-04-27T20:47:23.006344Z","shell.execute_reply.started":"2022-04-27T20:47:22.973028Z","shell.execute_reply":"2022-04-27T20:47:23.005726Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:23.007554Z","iopub.execute_input":"2022-04-27T20:47:23.007761Z","iopub.status.idle":"2022-04-27T20:47:23.012111Z","shell.execute_reply.started":"2022-04-27T20:47:23.007729Z","shell.execute_reply":"2022-04-27T20:47:23.011487Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nfor epoch in range(epochs):\n    running_loss = 0.0\n    model.train()\n    model.cuda()\n    for i, (batch, labels) in enumerate(train_loader):\n        batch = batch.to(torch.device(\"cuda\"))\n        labels = labels.to(torch.device(\"cuda\"))\n        optimizer.zero_grad()\n        y_pred =  model(batch)\n        entropy_loss = nn.CrossEntropyLoss()\n        loss = entropy_loss(y_pred,labels)\n        loss.backward()\n        optimizer.step()\n      \n        running_loss += loss.item()\n        if i % 1000 == 999:\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 500))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:47:23.013139Z","iopub.execute_input":"2022-04-27T20:47:23.013649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"./save_model\"\ntorch.save(model.state_dict(), PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = CNN(num_classes)\nmodel.load_state_dict(torch.load(PATH))\n\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\n\noutputs = model(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true = 0\ntotal = 0\nentropy_loss = nn.CrossEntropyLoss()\nbirds = []\nid = []\n\nwith torch.no_grad():\n    for i, data in enumerate(valid_loader):\n      images, labels = data\n\n      outputs = model(images)\n      loss = entropy_loss(outputs,labels)\n      id.append(i)\n      birds.append(loss.item())\n      _, predicted = torch.max(outputs.data, 1)\n      total += labels.size(0)\n      true += (predicted == labels).sum().item()\n\nprint('Accuracy of this network on validation images: %d %%' % (100 * true / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}